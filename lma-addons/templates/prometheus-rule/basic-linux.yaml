{{- if and .Values.prometheusRules.alert.enabled .Values.prometheusRules.alert.rule.basicLinux }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    prometheus-operator-validated: "true"
  name: basic-linux
  namespace:  {{ .Values.prometheusRules.alert.namespace }}
spec:
#basic_linux:
  groups:
  - name: basic_linux.rules
    rules:
    - alert: node_filesystem_full_80percent
      expr: sort(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"} < node_filesystem_size_bytes{fstype =~ "xfs|ext[34]"} * 0.2) / 1024 ^ 3
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} device {{`{{ $labels.device }}`}} on {{`{{ $labels.mountpoint }}`}} got less than 10% space left on its filesystem. ({{`{{ $labels.taco_cluster  }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: Filesystem is running out of space soon. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_filesystem_full_in_4h
      expr: predict_linear(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"}[1h], 4 * 3600) <= 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} device {{`{{ $labels.device }}`}} on {{`{{ $labels.mountpoint }}`}} is running out of space of in approx. 4 hours ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: Filesystem is running out of space in 4 hours. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_filedescriptors_full_in_3h
      expr: predict_linear(node_filefd_allocated[1h], 3 * 3600) >= node_filefd_maximum
      for: 20m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} is running out of available file descriptors in approx. 3 hours ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}} is running out of available file descriptors in 3 hours. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_load1_90percent
      expr: node_load1 / ON(instance, taco_cluster) count(node_cpu_seconds_total{mode="system"}) BY (instance,taco_cluster) >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} is running with > 90% total load for at least 1h. ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: Running on high load. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_cpu_util_90percent
      expr: instance:node_cpu:ratio >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has total CPU utilization over 90% for at least 1h. ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: High CPU utilization. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_ram_using_90percent
      expr: node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes < node_memory_MemTotal_bytes * 0.1
      for: 30m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} is using at least 90% of its RAM for at least 30 minutes now. ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: Using lots of RAM. ({{`{{ $labels.taco_cluster }}`}})'
    # - alert: node_swap_using_80percent
    #   expr: node_memory_SwapTotal_bytes - (node_memory_SwapFree_bytes + node_memory_SwapCached_bytes) > node_memory_SwapTotal_bytes * 0.8
    #   for: 10m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       is using 80% of its swap space for at least 10 minutes now.'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       Running out of swap soon.'
    # - alert: node_high_cpu_load
    #   expr: node_load1 / ON(instance, taco_cluster) count(node_cpu_seconds_total{mode="system"}) BY (instance,taco_cluster) >= 0.8
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}} is running with load15 > 1 for at least 5 minutes: {{`{{$value}}`}}`}} ({{`{{ $labels.taco_cluster }}`}})'
    #     summary: '{{`{{ $labels.instance}}`}}: Running on high load: {{`{{ $value}}`}} ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_high_memory_load
      expr: (sum(node_memory_MemTotal_bytes)by(instance,taco_cluster) - sum(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)by(instance,taco_cluster)) / sum(node_memory_MemTotal_bytes)by(instance,taco_cluster) * 100 > 85
      for: 1m
      labels:
        severity: warning
      annotations:
        message: Host memory usage is {{`{{ humanize $value }}`}}%. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}. ({{`{{ $labels.taco_cluster }}`}})
        summary: Server memory is almost full ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_high_storage_load
      expr: (node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}) / node_filesystem_size_bytes{mountpoint="/"} * 100 > 85
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host storage usage is {{`{{ humanize $value }}`}}%. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}. ({{`{{ $labels.taco_cluster }}`}})
        summary: Server storage is almost full ({{`{{ $labels.taco_cluster }}`}})
    # - alert: node_high_swap
    #   expr: (node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) < (node_memory_SwapTotal_bytes * 0.4)
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: Host system has a high swap usage of {{`{{ humanize $value }}`}}. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}.
    #     summary: Server has a high swap usage
    - alert: node_high_network_drop_rcv
      expr: increase(node_network_receive_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network reception ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}} ({{`{{ $labels.taco_cluster }}`}})
        summary: Server has a high receive drop ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_high_network_drop_send
      expr: increase(node_network_transmit_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network transmission ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}} ({{`{{ $labels.taco_cluster }}`}})
        summary: Server has a high transmit drop ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_high_network_errs_rcv
      expr: node_network_receive_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network reception ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}} ({{`{{ $labels.taco_cluster }}`}})
        summary: Server has unusual high reception errors ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_high_network_errs_send
      expr: node_network_transmit_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network transmission ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}} ({{`{{ $labels.taco_cluster }}`}})
        summary: Server has unusual high transmission errors ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_network_conntrack_usage_80percent
      expr: sort(node_nf_conntrack_entries{job="node-exporter"} > node_nf_conntrack_entries_limit{job="node-exporter"}  * 0.8)
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has network conntrack entries of {{`{{ $value }}`}} which is more than 80% of maximum limit ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}:
          available network conntrack entries are low. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_entropy_available_low
      expr: node_entropy_available_bits < 300
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} has available entropy bits of {{`{{ $value }}`}} which is less than required of 300 ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: is low on entropy bits. ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_hwmon_high_cpu_temp
      expr: node_hwmon_temp_crit_celsius*0.9 - node_hwmon_temp_celsius < 0 OR node_hwmon_temp_max_celsius*0.95 - node_hwmon_temp_celsius < 0
      for: 5m
      labels:
        severity: critical
      annotations:
        message: '{{`{{ $labels.instance }}`}} reports hwmon sensor {{`{{ $labels.sensor }}`}}/{{`{{ $labels.chip }}`}} temperature value is nearly critical: {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: Sensor {{`{{ $labels.sensor }}`}}/{{`{{$labels.chip }}`}} temp is high: {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_vmstat_paging_rate_high
      expr: irate(node_vmstat_pgpgin[5m]) > 80
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has a memory paging rate of change higher than 80%: {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: memory paging rate is high: {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
    # xfs사용하는 곳 없음
    # - alert: node_xfs_block_allocation_high
    #   expr: 100*(node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"} / (node_xfs_extent_allocation_blocks_freed_total{job="node-exporter", instance=~"172.17.0.1.*"} + node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"})) > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       has xfs allocation blocks higher than 80%: {{`{{$value}}`}}'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       xfs block allocation high: {{`{{ $value}}`}}'
    - alert: node_network_bond_slaves_down
      expr: node_bonding_slaves - node_bonding_slaves_active > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.master }}`}} is missing {{`{{ $value }}`}} slave interface(s). ({{`{{ $labels.taco_cluster }}`}})'
        summary: 'Instance {{`{{ $labels.instance }}`}}: {{`{{ $labels.master }}`}} missing {{`{{ $value }}`}} slave interface(s) ({{`{{ $labels.taco_cluster }}`}})'
    # - alert: node_numa_memory_used
    #   expr: 100*node_memory_numa_MemUsed_bytes / node_memory_numa_MemTotal_bytes > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       has more than 80% NUMA memory usage: {{`{{ $value}}`}} ({{`{{ $labels.taco_cluster }}`}})'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       has high NUMA memory usage: {{`{{ $value}}`}} ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_ntp_clock_skew_high
      expr: abs(node_ntp_drift_seconds) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} has time difference of more than 2 seconds compared to NTP server: {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
        summary: '{{`{{ $labels.instance }}`}}: time is skewed by : {{`{{ $value }}`}} seconds ({{`{{ $labels.taco_cluster }}`}})'
    - alert: node_disk_read_latency
      expr: (rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.device }}`}} has a high read latency of {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
        summary: High read latency observed for device {{`{{ $labels.device }}`}} ({{`{{ $labels.taco_cluster }}`}})
    - alert: node_disk_write_latency
      expr: (rate(node_disk_write_time_seconds_total{device!~"rbd.*"}[5m]) / rate(node_disk_writes_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.device }}`}} has a high write latency of {{`{{ $value }}`}} ({{`{{ $labels.taco_cluster }}`}})'
        summary: High write latency observed for device {{`{{ $labels.device }}`}} ({{`{{ $labels.taco_cluster }}`}})
{{- end }}
