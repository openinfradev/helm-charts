{{- if and .Values.prometheusRules.alert.enabled .Values.prometheusRules.alert.rule.basicLinux }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  annotations:
    prometheus-operator-validated: "true"
  name: basic-linux
  namespace:  {{ .Values.prometheusRules.alert.namespace }}
spec:
#basic_linux:
  groups:
  - name: basic_linux.rules
    rules:
    - alert: node_filesystem_full_80percent
      expr: sort(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"} < node_filesystem_size_bytes{fstype =~ "xfs|ext[34]"} * 0.2) / 1024 ^ 3
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} device {{`{{ $labels.device }}`}} on {{`{{ $labels.mountpoint }}`}} got less than 10% space left on its filesystem.'
        summary: '{{`{{ $labels.instance }}`}}: Filesystem is running out of space soon.'
    - alert: node_filesystem_full_in_4h
      expr: predict_linear(node_filesystem_free_bytes{fstype =~ "xfs|ext[34]"}[1h], 4 * 3600) <= 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} device {{`{{ $labels.device }}`}} on {{`{{ $labels.mountpoint }}`}} is running out of space of in approx. 4 hours'
        summary: '{{`{{ $labels.instance }}`}}: Filesystem is running out of space in 4 hours.'
    - alert: node_filedescriptors_full_in_3h
      expr: predict_linear(node_filefd_allocated[1h], 3 * 3600) >= node_filefd_maximum
      for: 20m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} is running out of available file descriptors in approx. 3 hours'
        summary: '{{`{{ $labels.instance }}`}} is running out of available file descriptors in 3 hours.'
    - alert: node_load1_90percent
      expr: node_load1 / ON(instance) count(node_cpu_seconds_total{mode="system"}) BY (instance) >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} is running with > 90% total load for at least 1h.'
        summary: '{{`{{ $labels.instance }}`}}: Running on high load.'
    - alert: node_cpu_util_90percent
      expr: instance:node_cpu:ratio >= 0.9
      for: 1h
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has total CPU utilization over 90% for at least 1h.'
        summary: '{{`{{ $labels.instance }}`}}: High CPU utilization.'
    - alert: node_ram_using_90percent
      expr: node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes < node_memory_MemTotal_bytes * 0.1
      for: 30m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} is using at least 90% of its RAM for at least 30 minutes now.'
        summary: '{{`{{ $labels.instance }}`}}: Using lots of RAM.'
    # - alert: node_swap_using_80percent
    #   expr: node_memory_SwapTotal_bytes - (node_memory_SwapFree_bytes + node_memory_SwapCached_bytes) > node_memory_SwapTotal_bytes * 0.8
    #   for: 10m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       is using 80% of its swap space for at least 10 minutes now.'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       Running out of swap soon.'
    # - alert: node_high_cpu_load
    #   expr: node_load1 / ON(instance) count(node_cpu_seconds_total{mode="system"}) BY (instance) >= 0.8
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}} is running with load15 > 1 for at least 5 minutes: {{`{{$value}}`}}`}}'
    #     summary: '{{`{{ $labels.instance}}`}}: Running on high load: {{`{{ $value}}`}}'
    - alert: node_high_memory_load
      expr: (sum(node_memory_MemTotal_bytes)by(instance) - sum(node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes)by(instance)) / sum(node_memory_MemTotal_bytes)by(instance) * 100 > 85
      for: 1m
      labels:
        severity: warning
      annotations:
        message: Host memory usage is {{`{{ humanize $value }}`}}%. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}.
        summary: Server memory is almost full
    - alert: node_high_storage_load
      expr: (node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}) / node_filesystem_size_bytes{mountpoint="/"} * 100 > 85
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host storage usage is {{`{{ humanize $value }}`}}%. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}.
        summary: Server storage is almost full
    # - alert: node_high_swap
    #   expr: (node_memory_SwapTotal_bytes - node_memory_SwapFree_bytes) < (node_memory_SwapTotal_bytes * 0.4)
    #   for: 1m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: Host system has a high swap usage of {{`{{ humanize $value }}`}}. Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}.
    #     summary: Server has a high swap usage
    - alert: node_high_network_drop_rcv
      expr: increase(node_network_receive_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network reception ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}
        summary: Server has a high receive drop
    - alert: node_high_network_drop_send
      expr: increase(node_network_transmit_drop_total{device!="lo"}[2m]) > 100
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high drop in network transmission ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}
        summary: Server has a high transmit drop
    - alert: node_high_network_errs_rcv
      expr: node_network_receive_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network reception ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}
        summary: Server has unusual high reception errors
    - alert: node_high_network_errs_send
      expr: node_network_transmit_errs_total{device!="lo"} > 3000
      for: 30s
      labels:
        severity: warning
      annotations:
        message: Host system has an unusally high error rate in network transmission ({{`{{ humanize $value }}`}}). Reported by instance {{`{{ $labels.instance }}`}} of job {{`{{ $labels.job }}`}}
        summary: Server has unusual high transmission errors
    - alert: node_network_conntrack_usage_80percent
      expr: sort(node_nf_conntrack_entries{job="node-exporter"} > node_nf_conntrack_entries_limit{job="node-exporter"}  * 0.8)
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has network conntrack entries of {{`{{ $value }}`}} which is more than 80% of maximum limit'
        summary: '{{`{{ $labels.instance }}`}}:
          available network conntrack entries are low.'
    - alert: node_entropy_available_low
      expr: node_entropy_available_bits < 300
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} has available entropy bits of {{`{{ $value }}`}} which is less than required of 300'
        summary: '{{`{{ $labels.instance }}`}}: is low on entropy bits.'
    - alert: node_hwmon_high_cpu_temp
      expr: node_hwmon_temp_crit_celsius*0.9 - node_hwmon_temp_celsius < 0 OR node_hwmon_temp_max_celsius*0.95 - node_hwmon_temp_celsius < 0
      for: 5m
      labels:
        severity: critical
      annotations:
        message: '{{`{{ $labels.instance }}`}} reports hwmon sensor {{`{{ $labels.sensor }}`}}/{{`{{ $labels.chip }}`}} temperature value is nearly critical: {{`{{ $value }}`}}'
        summary: '{{`{{ $labels.instance }}`}}: Sensor {{`{{ $labels.sensor }}`}}/{{`{{$labels.chip }}`}} temp is high: {{`{{ $value }}`}}'
    - alert: node_vmstat_paging_rate_high
      expr: irate(node_vmstat_pgpgin[5m]) > 80
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.instance }}`}} has a memory paging rate of change higher than 80%: {{`{{ $value }}`}}'
        summary: '{{`{{ $labels.instance }}`}}: memory paging rate is high: {{`{{ $value }}`}}'
    # xfs사용하는 곳 없음
    # - alert: node_xfs_block_allocation_high
    #   expr: 100*(node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"} / (node_xfs_extent_allocation_blocks_freed_total{job="node-exporter", instance=~"172.17.0.1.*"} + node_xfs_extent_allocation_blocks_allocated_total{job="node-exporter", instance=~"172.17.0.1.*"})) > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       has xfs allocation blocks higher than 80%: {{`{{$value}}`}}'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       xfs block allocation high: {{`{{ $value}}`}}'
    - alert: node_network_bond_slaves_down
      expr: node_bonding_slaves - node_bonding_slaves_active > 0
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.master }}`}} is missing {{`{{ $value }}`}} slave interface(s).'
        summary: 'Instance {{`{{ $labels.instance }}`}}: {{`{{ $labels.master }}`}} missing {{`{{ $value }}`}} slave interface(s)'
    # - alert: node_numa_memory_used
    #   expr: 100*node_memory_numa_MemUsed_bytes / node_memory_numa_MemTotal_bytes > 80
    #   for: 5m
    #   labels:
    #     severity: warning
    #   annotations:
    #     message: '{{`{{ $labels.instance}}`}}
    #       has more than 80% NUMA memory usage: {{`{{ $value}}`}}'
    #     summary: '{{`{{ $labels.instance}}`}}:
    #       has high NUMA memory usage: {{`{{ $value}}`}}'
    - alert: node_ntp_clock_skew_high
      expr: abs(node_ntp_drift_seconds) > 2
      for: 5m
      labels:
        severity: warning
      annotations:
        message: '{{`{{ $labels.instance }}`}} has time difference of more than 2 seconds compared to NTP server: {{`{{ $value }}`}}'
        summary: '{{`{{ $labels.instance }}`}}: time is skewed by : {{`{{ $value }}`}} seconds'
    - alert: node_disk_read_latency
      expr: (rate(node_disk_read_time_seconds_total[5m]) / rate(node_disk_reads_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.device }}`}} has a high read latency of {{`{{ $value }}`}}'
        summary: High read latency observed for device {{`{{ $labels.device }}`}}
    - alert: node_disk_write_latency
      expr: (rate(node_disk_write_time_seconds_total{device!~"rbd.*"}[5m]) / rate(node_disk_writes_completed_total[5m])) > 40
      for: 5m
      labels:
        severity: page
      annotations:
        message: '{{`{{ $labels.device }}`}} has a high write latency of {{`{{ $value }}`}}'
        summary: High write latency observed for device {{`{{ $labels.device }}`}}
{{- end }}
