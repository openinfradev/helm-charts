# Default values for fluentbit-operator.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## Provide a name in place of fluentbit-operator for `app:` labels
##
nameOverride: ""

## Provide a k8s version to auto dashboard import script example: kubeTargetVersionOverride: 1.16.6
##
kubeTargetVersionOverride: ""

## Provide a name to substitute for the full names of resources
##
fullnameOverride: ""

## Labels to apply to all resources
##
commonLabels: {}
# scmhash: abc123
# myLabel: aakkmd

image:
  fluentbit:
    repository: ghcr.io/openinfradev/fluentbit
    tag: 25bc31cd4333f7f77435561ec70bc68e0c73a194
  exporter:
    repository: siim/logalert-exporter
    tag: v0.1.1
    pullPolicy: IfNotPresent
  elasticsearchTemplates: 
    repository: docker.io/openstackhelm/heat
    tag: newton
    pullPolicy: IfNotPresent


## Deploy a Fluentbit instance
##
fluentbit:
  enabled: true

  ## Annotations for Fluentbit
  ##
  annotations: {}

  ## Service account for Fluentbites to use.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/
  ##
  serviceAccount:
    create: true
    name: fluentbit

  daemonset:
    spec:
      ## Tolerations for use with node taints
      ## ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      ##
      tolerations: 
      - key: node-role.kubernetes.io/master
        operator: Exists
      - key: node-role.kubernetes.io/node
        operator: Exists

      ## Define which Nodes the Pods are scheduled on.
      ## ref: https://kubernetes.io/docs/user-guide/node-selection/
      ##
      nodeSelector: {}

      ## Secrets is a list of Secrets in the same namespace as the Fluentbit object, which shall be mounted into the Fluentbit Pods.
      ## The Secrets are mounted into /etc/fluentbit/secrets/. Secrets changes after initial creation of a Fluentbit object are not
      ## reflected in the running Pods. To change the secrets mounted into the Fluentbit Pods, the object must be deleted and recreated
      ## with the new list of secrets.
      ##
      secrets: []

      ## ConfigMaps is a list of ConfigMaps in the same namespace as the Fluentbit object, which shall be mounted into the Fluentbit Pods.
      ## The ConfigMaps are mounted into /etc/fluentbit/configmaps/.
      ##
      configMaps: []

      ## Standard objectâ€™s metadata. More info: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#metadata
      ## Metadata Labels and Annotations gets propagated to the fluentbit pods.
      ##
      podMetadata: {}
      # labels:
      #   app: fluentbit
      #   k8s-app: fluentbit

      ## Pod anti-affinity can prevent the scheduler from placing Fluentbit replicas on the same node.
      ## The default value "soft" means that the scheduler should *prefer* to not schedule two replica pods onto the same node but no guarantee is provided.
      ## The value "hard" means that the scheduler is *required* to not schedule two replica pods onto the same node.
      ## The value "" will disable pod anti-affinity so that no anti-affinity rules will be configured.
      podAntiAffinity: ""

      ## If anti-affinity is enabled sets the topologyKey to use for anti-affinity.
      ## This can be changed to, for example, failure-domain.beta.kubernetes.io/zone
      ##
      podAntiAffinityTopologyKey: kubernetes.io/hostname

      ## Assign custom affinity rules to the fluentbit instance
      ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
      ##
      affinity: {}
      # nodeAffinity:
      #   requiredDuringSchedulingIgnoredDuringExecution:
      #     nodeSelectorTerms:
      #     - matchExpressions:
      #       - key: kubernetes.io/e2e-az-name
      #         operator: In
      #         values:
      #         - e2e-az1
      #         - e2e-az2

      ## Resource limits & requests
      ##
      resources: {}
      # requests:
      #   memory: 400Mi

  job:
    spec:
      ## Define which Nodes the Pods are scheduled on.
      ## ref: https://kubernetes.io/docs/user-guide/node-selection/
      ##
      nodeSelector: {}
      ## Resource limits & requests
      ##
      resources: {}
      # requests:
      #   memory: 400Mi

  parsers: [ ]
  # - name: taco-syslog-parser-for-ubuntu # modified from syslog-rfc3164
  #   parser:
  #     regex:
  #       regex: '^(?<time>[^ ]* {1,2}[^ ]* [^ ]*) (?<host>[^ ]*) (?<ident>[a-zA-Z0-9_\/\.\-]*)(?:\[(?<pid>[0-9]+)\])?(?:[^\:]*\:)? *(?<message>.*)$'
  #       timeFormat: '%d/%b/%Y:%H:%M:%S %z'
  #       timeKeep: false
  #       timeKey: 'time'

  targetLogs: [ ]
  # - tag: kube.*
  #   bufferChunkSize: 2M
  #   bufferMaxSize: 5M
  #   do_not_store_as_default: false
  #   es_name: taco-es
  #   index: container
  #   memBufLimit: 20MB
  #   multi_index:
  #   - index: platform
  #     es_name: taco-es
  #     key: $kubernetes['namespace_name']
  #     value: kube-system|taco-system|lma|argo
  #   parser: docker
  #   path: /var/log/containers/*.log
  #   type: fluent
  # - tag: syslog.*
  #   es_name: taco-es
  #   index: syslog
  #   parser: syslog-rfc5424
  #   path: /var/log/syslog
  #   type: syslog
  outputs:
    es: []
    # - name: taco-es
    #   host: eck-elasticsearch-es-http
    #   port: 9200

    #   dedicatedUser: 
    #     username: taco-fluentbit
    #     password: password
    #     elasticPasswordSecret: eck-elasticsearch-es-elastic-user
      
    #   template:
    #     enabled: true
    #     ilms:
    #     - name: hot-delete-14days
    #       json:
    #         policy:
    #           phases:
    #             delete:
    #               actions:
    #                 delete: {}
    #               min_age: 14d
    #             hot:
    #               actions:
    #                 rollover:
    #                   max_age: 1d
    #                   max_docs: 5000000000
    #                   max_size: 30gb
    #                 set_priority:
    #                   priority: 100
    #     - name: hot-delete-7days
    #       json:
    #         policy:
    #           phases:
    #             delete:
    #               actions:
    #                 delete: {}
    #               min_age: 7d
    #             hot:
    #               actions:
    #                 rollover:
    #                   max_age: 1d
    #                   max_docs: 5000000000
    #                   max_size: 30gb
    #                 set_priority:
    #                   priority: 100
    #     - name: hot-delete-3hour
    #       json:
    #         policy:
    #           phases:
    #             delete:
    #               actions:
    #                 delete: {}
    #               min_age: 3h
    #             hot:
    #               actions:
    #                 rollover:
    #                   max_age: 1h
    #                   max_docs: 5000000000
    #                   max_size: 30gb
    #                 set_priority:
    #                   priority: 100
    #     templates:
    #     - name: platform
    #       json:
    #         index_patterns: platform*
    #         settings:
    #           index.lifecycle.name: hot-delete-14days
    #           index.lifecycle.rollover_alias: platform
    #           number_of_replicas: 1
    #           number_of_shards: 3
    #           refresh_interval: 30s
    #     - name: syslog
    #       json:
    #         index_patterns: syslog*
    #         settings:
    #           index.lifecycle.name: hot-delete-14days
    #           index.lifecycle.rollover_alias: syslog
    #           number_of_replicas: 1
    #           number_of_shards: 2
    #           refresh_interval: 30s
    kafka:
      enabled: false
      # broker: my-kafka-0.my-kafka-headless.lma.svc.cluster.local:9092,
      # topics: taco
    http:
      enabled: false
    loki: []
    # - name: taco-loki
    #   host: loki
    #   port: 3100

  alerts:
    enabled: false
    namespace: kube-system
    message: |-
      {{ $labels.container }} in {{ $labels.pod }} ({{ $labels.taco_cluster }}/{{ $labels.namespace }} ) generate a error due to log = {{ $labels.log }}
    summary: |-
      {{ $labels.container }} in {{ $labels.pod }} ({{ $labels.taco_cluster }}/{{ $labels.namespace }} ) generate a error
    # ******************** VERY IMPORTANT ************
    # current version of log-exporter(siim/logalert-exporter:v0.1.1) support only one notification
    # so you should not define more than one rule at installation
    # To define multiple phrase, make custom resouce for filter by hands
    rules:
    - name: example
      severity: critical
      regex: "update.?error"

  # Define cluster name which is shown in collected logs
  clusterName: demo-cluster
  exclude:
  - key: "$kubernetes['container_name']"
    value: kibana|elasticsearch|fluent-bit

podMonitor:
  ## If true, a ServiceMonitor CRD is created for a prometheus operator
  ## https://github.com/coreos/prometheus-operator
  ##
  enabled: false
  port: metrics
  path: /api/v1/metrics/prometheus
  #  namespace: monitoring  (defaults to use the namespace this chart is deployed to)
  labels: {}
  interval: 1m
  scheme: http
  tlsConfig: {}
  scrapeTimeout: 30s
  relabelings: []
  podTargetLabels: []

logExporter:
  enabled: false
  serviceMonitor:
    enabled: false
    interval: 1m
  spec:
    nodeSelector: {}
